
Структурные уровни в составе системы автоматической классификации текстов: обоснование гибридной модели, общее устройство, перспективы
 
Приходится констатировать, что современная турбулентная динамика развития NLP-инструментария, теории и лучших практик вычислительной лингвистики зачастую вынуждает коммерческие компании — как стартапы, так и enterprise-бизнесы — следовать «логике фронтира» и отдавать предпочтение той или иной новаторской архитектуре или языковому «движку» (language engine) безотносительно взвешенной оценки достоинств и недостатков предыдущих фаворитов индустрии, исходя преимущественно из отраслевой конъюнктуры и интегральных показателей бенчмаркинга новой технологии в наиболее значимых для организации задачах.
 
Применительно к инфраструктуре НЭБ, служащей целям автоматической систематизации и связывания знаний, по итогам анализа передовых разработок вычислительной лингвистики было принято решение взять на вооружение гибридную модель, имплементация которой на IV квартал 2020 года включает в себя два концептуально и технологически различных слоя, в ближнесрочной перспективе — три, призванных дать (и дающих) во взаимодействии синергетический эффект.
 
На первом, верхнем уровне системы задействуется маскированная (word-mask) предобученная языковая модель, наиболее передовой реализацией которой является BERT и которая оперирует токенизированными словами / лексемами. Необходимо пояснить идею «маскированности»: на стадии предобучения BERT в текстах, подаваемых ему на вход, случайным образом заменяются «масками» около 15% слов, и задача модели — верно заполнить лакуны. Условно говоря, с высокой вероятностью предположить, что во фразе «Коронавирус способен `[MASK]` центральную нервную систему» в составном предикативе недостаёт глагола «угнетать», «разрушать» или «повреждать».
 
Запуск BERT состоялся в 2018 году под эгидой подразделения Google Research. Опирается модель на так называемую архитектуру трансформера с совокупностью энкодеров, в основе которой лежит механизм внимания, как сокращающий издержки на вычисления, так и делающий итоговые "предсказания" модели более "контрастными". Модель успела показать значимые и статистически измеримые достижения в широком спектре задач обработки естественного языка. В частности, при генерации ответов на вопросы агента-человека, задаваемые в произвольной форме.
 

 
Маски слов (word mark) взамен пропущенных лексем используются, чтобы научить модель BERT верно заполнять лакуны.
 
Источник: [Jay Alammar. The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](http://jalammar.github.io/illustrated-bert/)
 
Подлежащей по отношению к BERT является лежит маскированная (symbol-mask) предобученная языковая модель, итеративной единицей является символ; соответственно, механизм маскирования в ней работает по сходным принципам, со скидкой на характер единицы. Пример действующей прикладной реализации такой архитектуры — ELMo, а в сценариях масштабной обработки текстовых массивов также модели fastText, рассчитанные на процессинг представлений слова в виде последовательностей символов (subword-level).
 
Архитектурно ELMo представляет собой рекуррентную нейронную сеть, которая учитывает в векторном представлении слова его контекст на более широком, синтагматическом горизонте: для генерации словесных представлений, они же эмбеддинги, в нём применяется глубокая двунаправленная модель LSTM (long short-term memory — длительная краткосрочная память), которая решает проблему с «короткой памятью» рекуррентных сетей и в меньшей степени страдает от всплесков и угасания градиентов.
 
С учётом состояния архивных источников, подлежащих оптическому распознаванию в соответствии с утверждёнными средне- и долгосрочными планами НЭБ, равно как и того, насколько ощутимое влияние оказывает качество распознавания на уровне знака на выходные результаты работы языковых моделей, есть веские предпосылки к того, чтобы задействовать в системе языковую модель посимвольного уровня: она доказанно повышает устойчивость к сбоям OCR при детекции отдельных знаков, к опечаткам и к ошибкам на стадии пост-OCR, обусловленным человеческим фактором.
 

 
Семантическая близость векторных представлений предложений, установленная с помощью языковой модели ELMo. Источник: TowardsDataScience.com.
 
 
Показательно, что при всех своих достоинствах BERT отличается выраженной неустойчивостью к малейшим повреждениям текста на уровне лексемы. Вместе с тем BERT в состоянии определить, что семантика помещённого в текст слова некогерентна окружению, т. е. зафиксировать и, возможно, исправить ошибку более высокоуровневую, однако модель способна осуществлять процедуры такого рода на уровне не более гранулярном, чем у языковой единицы, которым она базово оперирует. Ввиду самого своего устройства BERT лишён импликации, в соответствии с которой лексемы поддаются декомпозиции на структурные языковые единицы более низкого порядка, например морфемы, фонемы, семы и т. д. По сути, любая ошибка символьного порядка, допустим опечатка, формирует для него новую внутренне легитимную единицу в пределах текста; такая «слепота» предопределена самой концепцией seq2seq, или «последовательность к последовательности».
 
В свою очередь, действуя на символьном уровне, модели класса ELMo умеют достаточно надёжно и качественно работать в разрезе лексики, например экстрагировать из текста те или иные словосочетания (коллокации). Более того, они поддаются обучению до состояния, в котором становятся пригодными для детекции определённых сущностей — e.g. именованных. Однако ELMo, будучи RNN, обладает своими особенностями и ограничениями, в силу которых она не является универсальной: так, для полноценного функционирования она требует длительного обучения на гигантских массивах данных, а кроме того, склонна давать сбои на больших последовательностях символов.
 
С оговоркой об эмпирическом характере закономерности следует заключить, что в среднем чем гранулярнее операционный уровень языковой модели, тем больше, во всяком случае потенциально, у неё возможностей для коррекции подаваемых ей на вход текстов. Тем не менее такая «аберрационная гибкость» не единственный фактор, от которого должен зависеть состав системы автоматической классификации и анализа текстовых данных на естественном языке.
 
Отметим, гибридные подходы, подобные тому, который в 2020 году был сформирован и апробирован коллективом Лаборатории исследований и разработок в отношении системы автоклассификации текстов НЭБ, являются вариантом инженерной нормы касательно решения узкоцелевых NLP-задач, и, напротив, было бы недальновидно считать объективно оправданным индустриальным стандартом де-факто использование одной-единственной ядерной языковой модели или платформы. В качестве примера сошлёмся на комбинированную модель аспектного сентимент-анализа ALDONAr, включающую в себя тезаурус онтологий, BERT, задействуемый в целях генерации векторных представлений слов, а также два слоя свёрточной нейронной сети, или CNN, для расширенной детекции эмоциональной тональности текста [Мешкеле, Фрасинкар, 2020].
 
Как и было упомянуто ранее, на конец IV квартала 2020 года в системе автоклассификации текстов НЭБ функционально реализованы второй и третий уровни гибридной NLP-модели.
 
Также на сегодняшний день для автоклассификатора предусмотрено быстрое переключение опорной языковой модели по запросу — как в целях максимально оперативной отработки инженерных гипотез, так и в связи с чисто техническими ограничениями. Так, на текущий момент за отсутствием парка серверов с достаточным GPU-ресурсом поиск по корпусу единиц хранения НЭБ осуществляется посредством моделей fastText, с получением же требуемых аппаратных мощностей не составит труда инициировать обучение модели ELMo.
 
В пре-альфа-версии продукта с высокой по существующим отраслевым меркам точностью функционирует entity recognition — распознавание сущностей в тексте, в частности в выводе системы оцифровки архивов периодики (в пилотном проекте осуществлялась обработка подборки газеты «Красная Звезда» за 1941–1945 гг.).
 
Следующий шаг, намеченный на первую половину 2021 года, заключается в наложении третьего, верхнего функционального слоя на два существующих, а именно внедрение маскированной (mask-entity) языковой модели ERNIE-2, способной оперировать сущностями. Иными словами, ERNIE-2 обучается на уровне сущностей, например именованных, таких как ФИО, развёрнутый топоним, временной интервал и т. д. Упрощённо говоря, при предварительном добучении на вход системы подаётся фраза, из которой полностью изымается и подменяется «заглушкой» сущность (адрес, имя, иная лексичесая микроконструкция), каковую требуется восстановить.
 
Для того чтобы внедрение верхнеуровневого решения дало измеримый кумулятивный эффект, ожидаемо потребуется ресурсоёмкое обучение ERNIE-2 с высокой вычислительной нагрузкой (в том числе по той причине, что готовых предтренированных моделей ERNIE-2 для русского языка в мире на конец 2020 года не существует), однако оно всецело оправдано прагматически: модель располагает огромным потенциалом в восстановлении объектов, а также предполагает оперативную настройку языковой модели под решение конкретных лингвистических задач в режиме реального времени.
 
В дополнение к моделям автоматической систематизации текстов из корпуса НЭБ, подробно описанным в «Приложение к отчёту о реализации плана развития ФГИС НЭБ в III квартале 2020 г.», архитектура продукта дополнилась стеком и прикладным инструментарием для связывания именованных сущностей (англ. entity linking).
 
 
Связывание именованных сущностей
 
Наряду с детекцией и экстракцией различных сущностей, и в частности именованных — named entities, фундаментальную прагматическую значимость для НЭБ имеет связывание сущностей, или entity linking.
 
В сущности, связывание сущностей сводится к тому, что результаты анализа языкового материала проецируются на экстралингвистическую действительность и сопрягаются с её фактами. Если рассуждать в терминах логики и лингвистики, устанавливается, с каким денотатом (персоной, объектом, явлением и пр.) связан тот или иной сигнификат (сущность как дискурсивная единица). Простая иллюстрация: дано предложение «При всём при том Бендер — эксцентрик, склонный к гедонизму». Ни человек, ни ИИ сколь угодно высокого класса в отрыве от контекста не определят наверняка, о ком идёт речь — о самом знаменитом персонаже Ильфа и Петрова или о также небезызвестном роботе из мультсериала «Футурама». Однако качественно обученная на большом объёме структурированной и неструктурированной информации система автоматической систематизации и связывания знаний, весьма вероятно, даже с большей оперативностью и достоверностью, чем читатель, поймёт, о ком, скорее всего, говорится в тексте. В том числе благодаря оперативному анализу графа знаний, в который включена книга или другой объект хранения, где приведено процитированное предложение, его узкого и широкого контекста, метаданных и т. д. 
 
В составе гибридной модели автосистематизации связывание сущностей представляет собой промежуточный этап в трёхфазной процедуре (возможна и более дробная дифференциация стадий).
 
1. Распознавание сущностей (ER), а также детекция упоминаний, с отсечением мнимых вхождений: например, в коллокации «Джордж Буш старший» плохо обученная модель может вычленить короткую сущность «Джордж Буш» и атрибутировать её сыну упомянутой персоны, как более часто упоминаемому в периодике XXI века.
2. Связывание сущностей (EL), включая устранение двусмысленностей и разночтений: когда доподлинно установлено, что сущность «Джордж Буш старший» отсылает читателя к 41-му президенту США (а не, допустим, к его гипотетическому полному тёзке-фермеру из Алабамы).
3. Извлечение и фиксация отношений между сущностью и сопряжённым с ней объектом, их соположение с онтологиями и классификаторами внутри системы автосистематизации и связывания знаний.
Подходы к прикладной реализации entity linking разнятся в зависимости от решаемых задач — см., например, занимательный кейс [Ганеа, Колицас, Хофманн, 2018]. Методологиям связывания сущностей и избегания ошибок в этом процессе посвящён стремительно растущий в последние годы корпус академических и инженерно-прикладных публикаций, и среди прочего:
 
[Moro, A., Raganato, A., and Navigli, R. (2014). Entity linking meets word sense disambiguation: a unified approach. Transactions of the Association for Computational Linguistics, 2:231–244.]()
[Brasoveanu, A., Nixon, L. J. B., Weichselbraun, A., and Scharl, A. (2016). A regional news corpora for contextualized entity discovery and linking. In Proceedings of the Tenth International Conference on Language Resources and Evaluation LREC 2016, Portorož, Slovenia, May 23-28, 2016., pages 3333–3338]()
[Röder, M., Usbeck, R., Hellmann, S., Gerber, D., and Both, A. (2014). N3 - A collection of datasets for named entity recognition and disambiguation in the NLP interchange format. In Proceedings of the Ninth International Conference on Language Resources and Evaluation, LREC 2014, pages 3529–3533]()
[Xianpei Han, and Le Sun, A Generative Entity-Mention Model for Linking Entities with Knowledge Base (2011), 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies]()




Таким образом, ключевая задача верхнеуровневых NLP-моделей в архитектуре системы — осуществлять первичную детекцию сущностей внутри текста и производить коррекцию в спорных ситуациях (возможность сбоев на стадии пост-OCR, ошибок со стороны эксперта-асессора).
 
Далее, после экстракции заданного спектра сущностей из текстов, предлагается строить entity linking и более тонкую работу с семантикой этих текстов на основе темпоральных конструкций. Инженерная группа ЛИР сочла такой путь развития архитектуры предпочтительным по той причине, что временные конструкции представляют собой (а) сравнительно легко формализуемые и (б) регулярные и значимые средства выстраивания причинно-следственных связей в повествовании на естественном языке. Упрощённо говоря, разместив упоминаемые в тексте события на временной шкале, мы существенно упрощаем дифференциацию потенциальных причин и потенциальных следствий и выстраивания гипотез на предмет валидности такой каузации (в норме причина хронологически идёт позже следствия, при условии что анализу подвергается не фантастический рассказ о временных парадоксах).
 
Таким образом, date / time entity recognition в пределах текста становится не менее, а возможно, и более приоритетной задачей, чем анализ несущих грамматических единиц (детекция предикатов, именных категорий и т. д.)
 
Среди важных полезных последствий выделения и интерпретации темпоральных конструкций выделим также следующее: такая обработка текста — важный шаг к организации машинного сторителлинга в едином пространстве знаний. Когнитивно-эвристические особенности человеческого разума располагают его к тому, чтобы организовывать потоки событий, фактов, персон и объектов в структурированные последовательные истории, на чём зиждутся и древнейшие мифологические воззрения народов мира, и классическая драматургия, и customer journey в современных цифровых сервисах. В свою очередь, верифицированное представление о временной, а значит, в значительной части и причинно-следственной соотнесённости как единиц хранения в НЭБ, так и сущностей внутри каждого отдельного текста или его фрагмента в перспективе даёт возможность создавать истории, не только показывающие взаимную комплементарность своих составных частей (благодаря работе рекомендательных механизмов и семантико-онтологическим связям между ними), но и глубоко увлекающие пользователя цифровой библиотеки на эмоциональном уровне.
 
Резюме: на текущем уровне в системе автоматической классификации и связывания знаний НЭБ на двух иерархических уровнях производится обучение и доводка лингвистических моделей, которые выделяют в анализируемых текстах определённые сущности. На конец IV квартала 2020 года также ведётся работа по алгоритмизированному распознаванию ряда темпоральных конструкций (от точных формальных timestamps типа «1565-1577 гг.» до относительных вида «на прошлое 8 Марта»), что служит подготовкой к следующему шагу в машинной интерпретации логико-семантического пространства текста, поскольку подобные временные маркеры крайне важными и в статистическом изводе достоверными источниками знания о каузальной структуре текста или совокупности текстов (собрания сочинений, тематической коллекции изданий, тематических подборок и др.), а благо количество фундаментальных сценариев причинно-следственных связей на высоком уровне концептуализации ограниченно, экстракция и связывание временных сущностей способны значительно улучшить интерпретативные возможности действующего NLP-стека НЭБ.
 
Отсюда проистекают ещё два приоритета концептуально-технологического характера, которые намечены к разработке в ЛИР на 2021 год.


1.  Контекстуальное связывание (contextual linking) сущностей и других единиц знания и контекстуальное обучение языковых моделей. Подобными технологиями в последние несколько лет плотно занимаются зарубежные IT-гиганты, включая Microsoft, в своих проектах на ниве инженерии знаний.
 
    В наиболее широком понимании контекстуальное связывание мыслится рабочей группой Лаборатории исследований и разработки как один из инструментов, который позволит конструировать «подпространство знаний» под каждого отдельно взятого читателя НЭБ по запросу (on-demand), исходя из того, как его образовательные, познавательные или развлекательные потребности, выраженные напрямую вербально или косвенно через действия в интерфейсе, и генерируемые ими семантическими поля соотносятся с пространством знаний цифровой библиотеки, что обогащает опыт пользователя и даёт ему возможность извлекать больше добавленной ценности из НЭБ.
 
    Примечание: о комбинировании моделей семантических полей с древовидным подходом в существующих классификаторах за счёт индексации на основе пространств с отрицательной кривизной подробнее см. в «Приложении к отчёту о реализации плана развития ФГИС НЭБ в III квартале 2020 г.»
 
2.  Так называемый reasoning, или «машинные умозаключения». Вкратце — подразумеваются такие ML-решения, которые, полагаясь на объём соотнесённых между собой сущностей текста (entities), в состоянии делать выводы, обобщающие, или дополняющие, или реконструирующие пропущенные части underlay-данных. То есть, с известной долей допущения, способна делать аналитические выкладки, характерные для человека. Архитектурные решения, на которых могут быть реализованы «машинные умозаключения», крайне разнообразные, равно как и сферы их применения — например, уже сегодня достижимо использование ИИ в объектно-ориентированных суждениях применительно к некоторым физическим задачам [коллектив Google DeepMind, 2016]
 
    В своём подходе к reasoning Лаборатория исследований и разработки НЭБ ориентируется в первую очередь на опыт европейской цифровой библиотеки Europeana (см. стратегию организации на 2020–2025 гг. и её модель управления данными), принимая во внимание просчёты, допущенные её командой при осуществлении проекта, и неоптимальные в долгосрочной перспективе решения.
 
